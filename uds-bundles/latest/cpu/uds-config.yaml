variables:
  text-embeddings:
    gpu_limit: 0

  whisper:
    gpu_limit: 0

  rag:
    model: llama-cpp-python
    ssl_verification: "false" # if certs exist in-cluster, make true
    response_mode: "raw" # default mode for query endpoint
    temperature: 0 # refine method temperature for vllm
    max_output: 2048
    context_window: 4096
    chunk_size: 512
    overlap_size: 64
    embedding_model_name: text-embeddings
    top_k: 20

  leapfrogai-ui:
    domain: https://ai.uds.dev
    model: llama-cpp-python
    concurrent_requests: "false"
    ai4ns_branding: "false"
    leapfrogai_rag_url: http://rag.leapfrogai.svc.cluster.local:8000
    max_tokens: 8192