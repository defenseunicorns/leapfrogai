# yaml-language-server: $schema=https://raw.githubusercontent.com/zarf-dev/zarf/main/zarf.schema.json
kind: ZarfPackageConfig
metadata:
  name: vllm
  version: "###ZARF_PKG_TMPL_IMAGE_VERSION###"
  description: >
    vLLM model

constants:
  - name: IMAGE_VERSION
    value: "###ZARF_PKG_TMPL_IMAGE_VERSION###"

components:
  - name: vllm-model
    required: true
    charts:
      - name: vllm-model
        namespace: leapfrogai
        localPath: chart
        releaseName: vllm-model
        # x-release-please-start-version
        version: 0.9.2
        # x-release-please-end
        valuesFiles:
          - "vllm-values.yaml"
    images:
      - ghcr.io/defenseunicorns/leapfrogai/vllm:###ZARF_PKG_TMPL_IMAGE_VERSION###
      - cgr.dev/chainguard/bash:latest
    dataInjections:
      - source: .model/
        target:
          namespace: leapfrogai
          selector: app=lfai-vllm
          container: data-loader
          path: /data/.model
        compress: true
    actions:
      onCreate:
        before:
          # NOTE: This assumes python is installed and in $PATH and 'huggingface_hub[cli,hf_transfer]' has been installed
          - cmd: python src/model_download.py
            env:
              - LAI_REPO_ID=TheBloke/Synthia-7B-v2.0-GPTQ
              - LAI_REVISION=gptq-4bit-32g-actorder_True
              - LAI_QUANTIZATION=gptq
              - LAI_HF_HUB_ENABLE_HF_TRANSFER=1
