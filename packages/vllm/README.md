# LeapfrogAI vLLM Backend

A LeapfrogAI API-compatible [vLLM](https://github.com/vllm-project/vllm) wrapper for quantized and un-quantized model inferencing across GPU infrastructures.


# Usage

:construction_worker: This documentation is still under construction. :construction_worker:

