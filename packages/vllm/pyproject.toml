[project]
name = "lfai-vllm"
description = "A LeapfrogAI API-compatible VLLM wrapper for quantized and un-quantized model inferencing across GPU infrastructures."

# x-release-please-start-version
version = "0.12.0"
# x-release-please-end

dependencies = [
    "pydantic == 2.8.2",
    "vllm == 0.4.2",
    "python-dotenv == 1.0.1",
    "aiostream == 0.5.2",
    "leapfrogai-sdk",
    "confz == 2.0.1",
]
requires-python = "~=3.11"
readme = "README.md"

[project.optional-dependencies]
dev = ["confz == 2.0.1", "huggingface_hub[cli,hf_transfer] == 0.24.5"]

[tool.pip-tools]
generate-hashes = true

[tool.setuptools]
packages = ["leapfrogai_sdk"]
package-dir = { "" = "../../src" }

[tool.pytest.ini_options]
addopts = ["--import-mode=importlib"]

[tool.ruff]
target-version = "py311"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
