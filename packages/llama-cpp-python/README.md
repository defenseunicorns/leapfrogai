# LeapfrogAI llama-cpp-python Backend

A LeapfrogAI API-compatible [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) w wrapper for quantized and un-quantized model inferencing across CPU infrastructures.


# Usage

:construction_worker: This documentation is still under construction. :construction_worker:

