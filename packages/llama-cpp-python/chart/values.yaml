# Default values for chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: ghcr.io/defenseunicorns/leapfrogai/llama-cpp-python
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  # x-release-please-start-version
  tag: 0.11.0
  # x-release-please-end

nameOverride: llama-cpp-python
fullnameOverride: ""

env:
  - name: LFAI_LOG_LEVEL
    value: "INFO"

podSecurityContext:
  runAsNonRoot: true
  fsGroup: 65532

securityContext:
  runAsUser: 65532
  runAsGroup: 65532
  runAsNonRoot: true
  capabilities:
    drop:
      - ALL

service:
  type: ClusterIP
  port: 50051

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    cpu: 0
    memory: 0
    nvidia.com/gpu: 0
  requests:
    cpu: 0
    memory: 0
    nvidia.com/gpu: 0

replicaCount: 1

podAnnotations: {}

nodeSelector: {}

tolerations: []

affinity: {}

strategy:
  rollingUpdate:
    maxUnavailable: 0
  type: RollingUpdate

persistence:
  size: 15Gi
  accessModes: ReadWriteOnce
  storageClass: "local-path"

modelInjectionContainer:
  securityContext:
    runAsUser: 65532
    runAsGroup: 65532

  resources:
    limits:
      memory: "128Mi"
      cpu: "500m"
    requests:
      memory: "64Mi"
      cpu: "200m"

  volumeMounts:
    - name: leapfrogai-pv-storage
      mountPath: /data
