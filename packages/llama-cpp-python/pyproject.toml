[project]
name = "lfai-llama-cpp-python"
version = "0.2.1"
description = "A LeapfrogAI API-compatible llama-cpp-python wrapper for quantized and un-quantized model inferencing on CPU infrastructures."

dependencies = [
    "llama-cpp-python == 0.2.28",
    "leapfrogai-sdk == 0.1.0",
]
requires-python = "~=3.11"
readme = "README.md"

[tool.pip-tools]
generate-hashes = true

[tool.setuptools]
packages = ["leapfrogai_sdk"]
package-dir = {"" = "../../src"}

[tool.pytest.ini_options]
addopts = ["--import-mode=importlib"]

[tool.ruff]
target-version = "py311"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
