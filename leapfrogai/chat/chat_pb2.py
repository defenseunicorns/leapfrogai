# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: chat.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\nchat.proto\x12\x04\x63hat\"\x1d\n\x0b\x43hatRequest\x12\x0e\n\x06inputs\x18\x01 \x03(\t\"\x14\n\x04\x43hat\x12\x0c\n\x04\x63hat\x18\x01 \x03(\x02\"(\n\x0c\x43hatResponse\x12\x18\n\x04\x63hat\x18\x01 \x03(\x0b\x32\n.chat.Chat\"E\n\x0eOpenAIChatItem\x12\"\n\x04role\x18\x01 \x01(\x0e\x32\x14.chat.OpenAIChatRole\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\"\xf2\x02\n\x1bOpenAIChatCompletionRequest\x12\r\n\x05model\x18\x01 \x01(\t\x12(\n\nchat_items\x18\x02 \x03(\x0b\x32\x14.chat.OpenAIChatItem\x12\x13\n\x0btemperature\x18\x03 \x01(\x02\x12\r\n\x05top_p\x18\x04 \x01(\x02\x12\t\n\x01n\x18\x05 \x01(\x05\x12\x0e\n\x06stream\x18\x07 \x01(\x08\x12\x0c\n\x04stop\x18\x08 \x03(\t\x12\x12\n\nmax_tokens\x18\t \x01(\x05\x12\x18\n\x10presence_penalty\x18\n \x01(\x02\x12\x19\n\x11\x66requency_penalty\x18\x0b \x01(\x02\x12\x44\n\nlogit_bias\x18\x0c \x03(\x0b\x32\x30.chat.OpenAIChatCompletionRequest.LogitBiasEntry\x12\x0c\n\x04user\x18\r \x01(\t\x1a\x30\n\x0eLogitBiasEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x05:\x02\x38\x01\"g\n\x16OpenAICompletionChoice\x12\r\n\x05index\x18\x01 \x01(\x05\x12\'\n\tchas_item\x18\x02 \x01(\x0b\x32\x14.chat.OpenAIChatItem\x12\x15\n\rfinish_reason\x18\x03 \x01(\t\"O\n\x05Usage\x12\x15\n\rprompt_tokens\x18\x01 \x01(\x05\x12\x19\n\x11\x63ompletion_tokens\x18\x02 \x01(\x05\x12\x14\n\x0ctotal_tokens\x18\x03 \x01(\x05\"\x8f\x01\n\x15\x43hatCompletionRequest\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06object\x18\x02 \x01(\t\x12\x0f\n\x07\x63reated\x18\x03 \x01(\x03\x12-\n\x07\x63hoices\x18\x04 \x03(\x0b\x32\x1c.chat.OpenAICompletionChoice\x12\x1a\n\x05usage\x18\x05 \x01(\x0b\x32\x0b.chat.Usage*C\n\x0eOpenAIChatRole\x12\x08\n\x04USER\x10\x00\x12\n\n\x06SYSTEM\x10\x01\x12\x0c\n\x08\x46UNCTION\x10\x02\x12\r\n\tASSISTANT\x10\x03\x32\x88\x01\n\x0c\x43hatsService\x12\x37\n\x0e\x43hatCompletion\x12\x11.chat.ChatRequest\x1a\x12.chat.ChatResponse\x12?\n\x14\x43hatCompletionStream\x12\x11.chat.ChatRequest\x1a\x12.chat.ChatResponse0\x01\x42\x37Z5github.com/defenseunicorns/leapfrogai/pkg/client/chatb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'chat_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'Z5github.com/defenseunicorns/leapfrogai/pkg/client/chat'
  _OPENAICHATCOMPLETIONREQUEST_LOGITBIASENTRY._options = None
  _OPENAICHATCOMPLETIONREQUEST_LOGITBIASENTRY._serialized_options = b'8\001'
  _globals['_OPENAICHATROLE']._serialized_start=891
  _globals['_OPENAICHATROLE']._serialized_end=958
  _globals['_CHATREQUEST']._serialized_start=20
  _globals['_CHATREQUEST']._serialized_end=49
  _globals['_CHAT']._serialized_start=51
  _globals['_CHAT']._serialized_end=71
  _globals['_CHATRESPONSE']._serialized_start=73
  _globals['_CHATRESPONSE']._serialized_end=113
  _globals['_OPENAICHATITEM']._serialized_start=115
  _globals['_OPENAICHATITEM']._serialized_end=184
  _globals['_OPENAICHATCOMPLETIONREQUEST']._serialized_start=187
  _globals['_OPENAICHATCOMPLETIONREQUEST']._serialized_end=557
  _globals['_OPENAICHATCOMPLETIONREQUEST_LOGITBIASENTRY']._serialized_start=509
  _globals['_OPENAICHATCOMPLETIONREQUEST_LOGITBIASENTRY']._serialized_end=557
  _globals['_OPENAICOMPLETIONCHOICE']._serialized_start=559
  _globals['_OPENAICOMPLETIONCHOICE']._serialized_end=662
  _globals['_USAGE']._serialized_start=664
  _globals['_USAGE']._serialized_end=743
  _globals['_CHATCOMPLETIONREQUEST']._serialized_start=746
  _globals['_CHATCOMPLETIONREQUEST']._serialized_end=889
  _globals['_CHATSSERVICE']._serialized_start=961
  _globals['_CHATSSERVICE']._serialized_end=1097
# @@protoc_insertion_point(module_scope)
