{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"all-minilm-l6-v2\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"ctransformers\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"Defense Unicorns\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"text-embedding-ada-002\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"Defense Unicorns\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"whisper-1\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"Defense Unicorns\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"mpt-7b-chat\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Put anything you want in `API key`\n",
    "openai.api_key = 'FreeTheModels'\n",
    "\n",
    "# Point to your own url\n",
    "openai.api_base = \"http://localhost:8080/openai\"\n",
    "print(openai.Model.list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `/completion` Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful programming assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you write a python program to download a series of files from s3 and search the contents of each file for email addresses?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Templates\n",
    "SYSTEM_FORMAT = \"<|im_start|>system\\n{}<|im_end|>\\n\"\n",
    "USER_FORMAT = \"<|im_start|>user\\n{}<|im_end|>\\n\"\n",
    "ASSISTANT_FORMAT = \"<|im_start|>assistant\\n{}<|im_end|>\\n\"\n",
    "# what gets appended to the end of the prompt to open the assistant's part of the conversation\n",
    "RESPONSE_PREFIX = ASSISTANT_FORMAT.split(\"{}\")[0]\n",
    "\n",
    "def chat_items_to_prompt(chat_items: list[dict]) -> str:\n",
    "    \"\"\"Converts a repeated ChatItem from a ChatCompletionRequest proto into a string\n",
    "\n",
    "    This is the actual string that gets fed into the model to generate the outputs\n",
    "    \"\"\"\n",
    "    prompt = \"\"\n",
    "    for item in chat_items:\n",
    "        if item[\"role\"] == \"system\":\n",
    "            prompt += SYSTEM_FORMAT.format(item[\"content\"])\n",
    "        elif item[\"role\"] == \"assistant\":\n",
    "            prompt += ASSISTANT_FORMAT.format(item[\"content\"])\n",
    "        elif item[\"role\"] == \"user\":\n",
    "            prompt += USER_FORMAT.format(item[\"content\"])\n",
    "        else:\n",
    "            logging.warning(\n",
    "                f\"ChatRole {item['role']} is not implemented for this model and this ChatItem will be ignored.\"\n",
    "            )\n",
    "    # add the response prefix to start the model's reponse\n",
    "    prompt += RESPONSE_PREFIX\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_items_to_prompt(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject  id=903c26c0-92ba-45cb-bdab-37fb37ab644a at 0x7f2ad0107dd0> JSON: {\n",
       "  \"id\": \"903c26c0-92ba-45cb-bdab-37fb37ab644a\",\n",
       "  \"object\": \"\",\n",
       "  \"created\": 1688959355,\n",
       "  \"model\": \"mpt-7b-chat\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"Sure, here's a sample Python program that downloads a series of files from S3 and searches their contents for email addresses:\\n```python\\nimport boto3\\nimport re\\n# Set up S3 client\\ns3 = boto3.client('s3')\\n# Define bucket and prefix\\nbucket_name = 'your-bucket-name'\\nprefix = 'your-prefix'\\n# Download files from S3\\nfiles = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)['Contents']\\n# Loop through files and search for email addresses\\nfor file in files:\\n    file_key = file['Key']\\n    file_obj = s3.get_object(Bucket=bucket_name, Key=file_key)['Body'].read()\\n    email_regex = r'\\\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Z|a-z]{2,}\\\\b'\\n    emails = re.findall(email_regex, file_obj)\\n    if emails:\\n        print(f\\\"Found email addresses in {file_key}: {emails}\\\")\\n```\\nThis program uses the `boto3` library to interact with S3. It first sets up an S3 client and defines the bucket name and prefix (i.e. the directory where the files are located). It then downloads all the files from S3 using the `list_objects_v2` method and loops through each file. For each file, it reads the contents using the `get_object` method and searches for email addresses using regular expressions. If any email addresses are found, it prints a message indicating which file and which email addresses were found.\",\n",
       "      \"index\": 0,\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"logprobs\": {\n",
       "        \"tokens\": null,\n",
       "        \"token_logprobs\": null,\n",
       "        \"top_logprobs\": null,\n",
       "        \"text_offset\": null\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 0,\n",
       "    \"completion_tokens\": 0,\n",
       "    \"total_tokens\": 0\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=\"mpt-7b-chat\",  # Select the appropriate engine for your needs\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a sample Python program that downloads a series of files from S3 and searches their contents for email addresses:\n",
      "```python\n",
      "import boto3\n",
      "import re\n",
      "# Set up S3 client\n",
      "s3 = boto3.client('s3')\n",
      "# Define bucket and prefix\n",
      "bucket_name = 'your-bucket-name'\n",
      "prefix = 'your-prefix'\n",
      "# Download files from S3\n",
      "files = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)['Contents']\n",
      "# Loop through files and search for email addresses\n",
      "for file in files:\n",
      "    file_key = file['Key']\n",
      "    file_obj = s3.get_object(Bucket=bucket_name, Key=file_key)['Body'].read()\n",
      "    email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
      "    emails = re.findall(email_regex, file_obj)\n",
      "    if emails:\n",
      "        print(f\"Found email addresses in {file_key}: {emails}\")\n",
      "```\n",
      "This program uses the `boto3` library to interact with S3. It first sets up an S3 client and defines the bucket name and prefix (i.e. the directory where the files are located). It then downloads all the files from S3 using the `list_objects_v2` method and loops through each file. For each file, it reads the contents using the `get_object` method and searches for email addresses using regular expressions. If any email addresses are found, it prints a message indicating which file and which email addresses were found.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I can help you with that. Here's a sample Python program that uses the boto3 library to download files from S3 and searches their contents for email addresses:\n",
      "```python\n",
      "import boto3\n",
      "import re\n",
      "# Set up S3 client\n",
      "s3 = boto3.client('s3')\n",
      "# Define bucket and key\n",
      "bucket_name = 'your-bucket-name'\n",
      "object_key = 'path/to/object'\n",
      "# Download file from S3\n",
      "response = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
      "file_content = response['Body'].read().decode('utf-8')\n",
      "# Search for email addresses in file content\n",
      "email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
      "emails = re.findall(email_regex, file_content)\n",
      "# Print found emails\n",
      "if emails:\n",
      "    print('Email addresses found:')\n",
      "    for email in emails:\n",
      "        print(email)\n",
      "else:\n",
      "    print('No email addresses found')\n",
      "```\n",
      "This program assumes that you have already set up an S3 bucket and uploaded the files you want to download. You will also need to have the boto3 library installed.\n",
      "The program downloads the file from S3, searches its contents for email addresses using regular expressions, and prints any found emails. If no emails are found, it prints a message saying so.<|im_end|>"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=\"mpt-7b-chat\",  # Select the appropriate engine for your needs\n",
    "    prompt=prompt,\n",
    "    stream=True  # this time, we set stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk[\"choices\"][0][\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `/chat/completions` Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-streaming Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject  id=4c41f73c-a5da-49cf-b302-7cacbb8e64ae at 0x7f2ad16ea5c0> JSON: {\n",
       "  \"id\": \"4c41f73c-a5da-49cf-b302-7cacbb8e64ae\",\n",
       "  \"object\": \"\",\n",
       "  \"created\": 1688959422,\n",
       "  \"model\": \"mpt-7b-chat\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Sure, here's a Python program that downloads a series of files from S3 and searches their contents for email addresses:\\n```python\\nimport boto3\\nimport re\\n# Set up S3 client\\ns3 = boto3.client('s3')\\n# Define bucket and prefix\\nbucket_name = 'your-bucket-name'\\nprefix = 'your-prefix'\\n# Download files from S3\\nfiles = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)['Contents']\\n# Search contents of each file for email addresses\\nfor file in files:\\n    file_key = file['Key']\\n    file_obj = s3.get_object(Bucket=bucket_name, Key=file_key)['Body'].read()\\n    email_regex = r'\\\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Z|a-z]{2,}\\\\b'\\n    emails = re.findall(email_regex, file_obj)\\n    print(f\\\"File '{file_key}' contains the following email addresses:\\\")\\n    for email in emails:\\n        print(email)\\n```\\nThis program uses the `boto3` library to interact with S3 and download files. It then searches the contents of each file for email addresses using regular expressions. The regular expression used here is `\\\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Z|a-z]{2,}\\\\b`, which matches most common email formats. The program prints out the file name and any email addresses it finds in the file.\"\n",
       "      },\n",
       "      \"finish_reason\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 0,\n",
       "    \"completion_tokens\": 0,\n",
       "    \"total_tokens\": 0\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model='mpt-7b-chat',\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a Python program that downloads a series of files from S3 and searches their contents for email addresses:\n",
      "```python\n",
      "import boto3\n",
      "import re\n",
      "# Set up S3 client\n",
      "s3 = boto3.client('s3')\n",
      "# Define bucket and prefix\n",
      "bucket_name = 'your-bucket-name'\n",
      "prefix = 'your-prefix'\n",
      "# Download files from S3\n",
      "files = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)['Contents']\n",
      "# Search contents of each file for email addresses\n",
      "for file in files:\n",
      "    file_key = file['Key']\n",
      "    file_obj = s3.get_object(Bucket=bucket_name, Key=file_key)['Body'].read()\n",
      "    email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
      "    emails = re.findall(email_regex, file_obj)\n",
      "    print(f\"File '{file_key}' contains the following email addresses:\")\n",
      "    for email in emails:\n",
      "        print(email)\n",
      "```\n",
      "This program uses the `boto3` library to interact with S3 and download files. It then searches the contents of each file for email addresses using regular expressions. The regular expression used here is `\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b`, which matches most common email formats. The program prints out the file name and any email addresses it finds in the file.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I can help you with that. Here's a sample Python program that downloads a series of files from S3 and searches their contents for email addresses:\n",
      "```python\n",
      "import boto3\n",
      "import re\n",
      "# Set up S3 client\n",
      "s3 = boto3.client('s3')\n",
      "# Define bucket and prefix\n",
      "bucket_name = 'your-bucket-name'\n",
      "prefix = 'your-prefix'\n",
      "# Download files from S3\n",
      "files = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)['Contents']\n",
      "# Loop through files and search for email addresses\n",
      "for file in files:\n",
      "    file_key = file['Key']\n",
      "    file_obj = s3.get_object(Bucket=bucket_name, Key=file_key)['Body'].read()\n",
      "    email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
      "    emails = re.findall(email_regex, file_obj)\n",
      "    print(f\"File {file_key}:\")\n",
      "    print(emails)\n",
      "```\n",
      "This program uses the `boto3` library to interact with S3. It first sets up an S3 client and defines the bucket name and prefix (i.e. the directory where the files are located). It then downloads all the files from S3 using the `list_objects_v2` method and loops through each file. For each file, it reads the contents using the `get_object` method and "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmpt-7b-chat\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     messages\u001b[39m=\u001b[39mmessages,\n\u001b[1;32m      4\u001b[0m     stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m  \u001b[39m# this time, we set stream=True\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m response:\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(chunk[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m], end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/work-ml/app/venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:166\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    167\u001b[0m         util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[1;32m    168\u001b[0m             line,\n\u001b[1;32m    169\u001b[0m             api_key,\n\u001b[1;32m    170\u001b[0m             api_version,\n\u001b[1;32m    171\u001b[0m             organization,\n\u001b[1;32m    172\u001b[0m             engine\u001b[39m=\u001b[39mengine,\n\u001b[1;32m    173\u001b[0m             plain_old_data\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mplain_old_data,\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m response\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     obj \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[1;32m    179\u001b[0m         response,\n\u001b[1;32m    180\u001b[0m         api_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m         plain_old_data\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mplain_old_data,\n\u001b[1;32m    185\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/work-ml/app/venv/lib/python3.10/site-packages/openai/api_requestor.py:692\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the response(s) and a bool indicating whether it is a stream.\"\"\"\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[39mif\u001b[39;00m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtext/event-stream\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/work-ml/app/venv/lib/python3.10/site-packages/openai/api_requestor.py:115\u001b[0m, in \u001b[0;36mparse_stream\u001b[0;34m(rbody)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_stream\u001b[39m(rbody: Iterator[\u001b[39mbytes\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m rbody:\n\u001b[1;32m    116\u001b[0m         _line \u001b[39m=\u001b[39m parse_stream_helper(line)\n\u001b[1;32m    117\u001b[0m         \u001b[39mif\u001b[39;00m _line \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Developer/work-ml/app/venv/lib/python3.10/site-packages/requests/models.py:865\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \n\u001b[1;32m    860\u001b[0m \u001b[39m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    863\u001b[0m pending \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_content(\n\u001b[1;32m    866\u001b[0m     chunk_size\u001b[39m=\u001b[39mchunk_size, decode_unicode\u001b[39m=\u001b[39mdecode_unicode\n\u001b[1;32m    867\u001b[0m ):\n\u001b[1;32m    869\u001b[0m     \u001b[39mif\u001b[39;00m pending \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    870\u001b[0m         chunk \u001b[39m=\u001b[39m pending \u001b[39m+\u001b[39m chunk\n",
      "File \u001b[0;32m~/Developer/work-ml/app/venv/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Developer/work-ml/app/venv/lib/python3.10/site-packages/urllib3/response.py:937\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 937\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content)\n\u001b[1;32m    938\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    939\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Developer/work-ml/app/venv/lib/python3.10/site-packages/urllib3/response.py:1077\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1077\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[1;32m   1078\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1079\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/work-ml/app/venv/lib/python3.10/site-packages/urllib3/response.py:1005\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1005\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline()  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1007\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model='mpt-7b-chat',\n",
    "    messages=messages,\n",
    "    stream=True  # this time, we set stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk[\"choices\"][0][\"message\"][\"content\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject  at 0x7f95f52c71a0> JSON: {\n",
       "  \"object\": \"\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"\",\n",
       "      \"embedding\": [\n",
       "        -0.042698976,\n",
       "        -0.026150815,\n",
       "        0.061529085,\n",
       "        -0.017067522,\n",
       "        0.039560657,\n",
       "        0.02837218,\n",
       "        0.031743776,\n",
       "        -0.0143780075,\n",
       "        0.08584679,\n",
       "        -0.001684193,\n",
       "        0.044729978,\n",
       "        0.1055661,\n",
       "        0.049236063,\n",
       "        0.013457378,\n",
       "        -0.11796918,\n",
       "        0.059610043,\n",
       "        0.10469074,\n",
       "        0.02386002,\n",
       "        -0.081601895,\n",
       "        -0.05700545,\n",
       "        -0.056711912,\n",
       "        -0.009005215,\n",
       "        0.084444866,\n",
       "        -0.0627069,\n",
       "        0.022999374,\n",
       "        0.04371579,\n",
       "        -0.08111302,\n",
       "        0.07167676,\n",
       "        0.061417066,\n",
       "        0.0068834806,\n",
       "        0.0067532244,\n",
       "        -0.0013206801,\n",
       "        0.012589719,\n",
       "        0.008909394,\n",
       "        -0.0050711646,\n",
       "        0.031988457,\n",
       "        0.031716038,\n",
       "        0.0700321,\n",
       "        -0.023534963,\n",
       "        0.04725706,\n",
       "        0.003399456,\n",
       "        -0.05707476,\n",
       "        0.035461646,\n",
       "        0.06411631,\n",
       "        0.048176814,\n",
       "        0.010704891,\n",
       "        -0.095382355,\n",
       "        -0.0567974,\n",
       "        -0.023594545,\n",
       "        0.025816323,\n",
       "        -0.021884834,\n",
       "        -0.07723609,\n",
       "        -0.02122747,\n",
       "        0.003935793,\n",
       "        -0.038713396,\n",
       "        0.06957578,\n",
       "        -0.01380568,\n",
       "        -0.12663253,\n",
       "        -0.020555886,\n",
       "        0.0150366295,\n",
       "        0.048488885,\n",
       "        0.03779843,\n",
       "        0.046989188,\n",
       "        -0.0005141045,\n",
       "        0.061515033,\n",
       "        0.010937038,\n",
       "        2.5452548e-05,\n",
       "        0.053959668,\n",
       "        -0.064295955,\n",
       "        0.014947985,\n",
       "        -0.004338892,\n",
       "        0.034483965,\n",
       "        -0.04576159,\n",
       "        0.060363747,\n",
       "        0.00080130255,\n",
       "        0.05134795,\n",
       "        -0.0400911,\n",
       "        -0.10367207,\n",
       "        0.030494466,\n",
       "        -0.04018658,\n",
       "        0.07187142,\n",
       "        -0.011124478,\n",
       "        0.056163833,\n",
       "        0.032128435,\n",
       "        0.0048074224,\n",
       "        -0.030420251,\n",
       "        0.031704452,\n",
       "        -0.08306933,\n",
       "        -0.027826687,\n",
       "        0.010819089,\n",
       "        0.040378477,\n",
       "        0.0059106434,\n",
       "        0.058612816,\n",
       "        0.002704726,\n",
       "        -0.09905934,\n",
       "        0.024978835,\n",
       "        -0.014045202,\n",
       "        0.015284118,\n",
       "        -0.07106842,\n",
       "        0.088086225,\n",
       "        -0.0051670866,\n",
       "        -0.06668698,\n",
       "        0.05941421,\n",
       "        -0.034245625,\n",
       "        -0.0018160747,\n",
       "        -0.050833546,\n",
       "        0.028062139,\n",
       "        0.008320019,\n",
       "        -0.033484496,\n",
       "        -0.051063288,\n",
       "        0.008309966,\n",
       "        -0.036920432,\n",
       "        -0.11022484,\n",
       "        0.011112171,\n",
       "        0.002305758,\n",
       "        -0.060641702,\n",
       "        0.021689447,\n",
       "        -0.017732734,\n",
       "        0.044164743,\n",
       "        -0.018085767,\n",
       "        0.0066049146,\n",
       "        0.07920516,\n",
       "        -0.08225728,\n",
       "        0.05269051,\n",
       "        0.013987802,\n",
       "        -0.044674616,\n",
       "        0.0244644,\n",
       "        -2.358718e-33,\n",
       "        0.053829137,\n",
       "        0.01581004,\n",
       "        -0.0083985245,\n",
       "        0.079369225,\n",
       "        0.094315775,\n",
       "        -0.02908101,\n",
       "        -0.102281496,\n",
       "        0.033715926,\n",
       "        -0.083816215,\n",
       "        -0.032226194,\n",
       "        -0.0036060603,\n",
       "        0.01217847,\n",
       "        0.018589456,\n",
       "        0.05951213,\n",
       "        -0.048733212,\n",
       "        -0.08063913,\n",
       "        -0.018553918,\n",
       "        -0.031472772,\n",
       "        0.036013294,\n",
       "        -0.0218539,\n",
       "        -0.08115554,\n",
       "        0.016970465,\n",
       "        0.012102566,\n",
       "        -0.015378491,\n",
       "        -0.05153115,\n",
       "        0.046093784,\n",
       "        0.051863246,\n",
       "        -0.060348816,\n",
       "        -0.049712796,\n",
       "        0.035770893,\n",
       "        -0.075209856,\n",
       "        -0.05437032,\n",
       "        -0.028966473,\n",
       "        -0.06959318,\n",
       "        -0.04651377,\n",
       "        -0.02906336,\n",
       "        0.020094255,\n",
       "        -0.045049436,\n",
       "        0.006989864,\n",
       "        0.026230598,\n",
       "        0.019372048,\n",
       "        -0.05256309,\n",
       "        0.028336298,\n",
       "        -0.06982251,\n",
       "        -0.0041773785,\n",
       "        0.064263955,\n",
       "        0.032763887,\n",
       "        0.020458382,\n",
       "        0.022944944,\n",
       "        -0.021731988,\n",
       "        -0.019487977,\n",
       "        -0.027005926,\n",
       "        -0.02323236,\n",
       "        -0.012824931,\n",
       "        0.078217864,\n",
       "        -0.060492385,\n",
       "        -0.02305477,\n",
       "        0.04057144,\n",
       "        -0.0036536409,\n",
       "        -0.04254682,\n",
       "        -0.06611988,\n",
       "        -0.040588357,\n",
       "        -0.0057280217,\n",
       "        -0.01878385,\n",
       "        -0.023420561,\n",
       "        0.023731405,\n",
       "        -0.015569681,\n",
       "        -0.0107833315,\n",
       "        0.028487159,\n",
       "        -0.008812871,\n",
       "        -0.058929764,\n",
       "        0.044238564,\n",
       "        0.021664577,\n",
       "        -0.003957393,\n",
       "        -0.096052416,\n",
       "        0.017347751,\n",
       "        -0.023309967,\n",
       "        -0.053992096,\n",
       "        -0.03518163,\n",
       "        0.05231287,\n",
       "        -0.080861196,\n",
       "        -0.13603209,\n",
       "        0.045275286,\n",
       "        -0.065350875,\n",
       "        -0.03193755,\n",
       "        -0.12194109,\n",
       "        0.005592809,\n",
       "        -0.12584303,\n",
       "        0.06940793,\n",
       "        0.03186247,\n",
       "        -0.022916412,\n",
       "        -0.066831395,\n",
       "        -0.005216478,\n",
       "        0.00036739695,\n",
       "        0.058405656,\n",
       "        1.92378e-33,\n",
       "        0.03279592,\n",
       "        0.029777857,\n",
       "        -0.06384032,\n",
       "        0.04510895,\n",
       "        0.05166194,\n",
       "        0.058863588,\n",
       "        -0.028929645,\n",
       "        0.14688197,\n",
       "        0.0018175317,\n",
       "        0.055687476,\n",
       "        -0.029554583,\n",
       "        0.11637133,\n",
       "        0.076467484,\n",
       "        -0.08069461,\n",
       "        0.049512673,\n",
       "        -0.0009810054,\n",
       "        0.06767903,\n",
       "        0.059630543,\n",
       "        -0.027462227,\n",
       "        0.018576669,\n",
       "        -0.027322447,\n",
       "        -0.016003983,\n",
       "        -0.016699528,\n",
       "        0.05618768,\n",
       "        0.11250117,\n",
       "        0.07788829,\n",
       "        0.0084754415,\n",
       "        0.0129932845,\n",
       "        0.05863492,\n",
       "        -0.02564361,\n",
       "        0.004654173,\n",
       "        -0.016547857,\n",
       "        -0.00076271885,\n",
       "        -0.020219851,\n",
       "        -0.06631294,\n",
       "        0.022996882,\n",
       "        0.10205612,\n",
       "        0.0005067378,\n",
       "        0.010617938,\n",
       "        -0.03173786,\n",
       "        0.11088903,\n",
       "        0.017575206,\n",
       "        -0.029136064,\n",
       "        -0.014132568,\n",
       "        -0.01988618,\n",
       "        -0.008303567,\n",
       "        -0.06750719,\n",
       "        -0.03098014,\n",
       "        0.057931382,\n",
       "        0.026345875,\n",
       "        0.0067766956,\n",
       "        -0.036280397,\n",
       "        -0.026552249,\n",
       "        -0.071253546,\n",
       "        -0.05050525,\n",
       "        -0.05951787,\n",
       "        -0.02071858,\n",
       "        0.047777016,\n",
       "        0.04574142,\n",
       "        -0.036857437,\n",
       "        -0.04223355,\n",
       "        -0.018867124,\n",
       "        0.008408531,\n",
       "        -0.039025463,\n",
       "        0.052391082,\n",
       "        -0.059906777,\n",
       "        -0.025248006,\n",
       "        0.042847812,\n",
       "        -0.13949467,\n",
       "        -0.0321092,\n",
       "        0.033641163,\n",
       "        -0.00032619954,\n",
       "        -0.16229765,\n",
       "        0.026815152,\n",
       "        0.042951286,\n",
       "        -0.031770878,\n",
       "        0.100500196,\n",
       "        0.03128078,\n",
       "        -0.055263344,\n",
       "        0.014545699,\n",
       "        0.043158196,\n",
       "        -0.00799646,\n",
       "        0.005814274,\n",
       "        0.037164215,\n",
       "        0.10168903,\n",
       "        0.08159784,\n",
       "        -0.049886644,\n",
       "        0.013923664,\n",
       "        -0.014219511,\n",
       "        -0.019388294,\n",
       "        -0.06596432,\n",
       "        0.07854536,\n",
       "        -0.025708187,\n",
       "        0.10039806,\n",
       "        0.03937598,\n",
       "        -1.8437786e-08,\n",
       "        -0.03092343,\n",
       "        -0.021433612,\n",
       "        -0.058296423,\n",
       "        -0.004471891,\n",
       "        -0.036447063,\n",
       "        -0.010475321,\n",
       "        0.0032442613,\n",
       "        -0.09654642,\n",
       "        -0.056602284,\n",
       "        0.00897197,\n",
       "        0.12571111,\n",
       "        -0.020000366,\n",
       "        -0.032672014,\n",
       "        0.03973278,\n",
       "        0.007098078,\n",
       "        0.0035712793,\n",
       "        -0.00907492,\n",
       "        0.024215631,\n",
       "        0.044388544,\n",
       "        -0.001627713,\n",
       "        0.04367086,\n",
       "        0.07326952,\n",
       "        0.019079791,\n",
       "        -0.0054480834,\n",
       "        -0.11357745,\n",
       "        0.039973043,\n",
       "        -0.039039504,\n",
       "        -0.019759757,\n",
       "        0.05750004,\n",
       "        -0.068365335,\n",
       "        0.017501485,\n",
       "        0.06229202,\n",
       "        -0.0050897226,\n",
       "        -0.007941011,\n",
       "        -0.051261373,\n",
       "        0.04318311,\n",
       "        0.022085123,\n",
       "        -0.047521945,\n",
       "        -0.026503451,\n",
       "        -0.052775443,\n",
       "        0.07936397,\n",
       "        0.014589201,\n",
       "        -0.046682984,\n",
       "        0.0030859467,\n",
       "        0.055123683,\n",
       "        -0.030179856,\n",
       "        0.10364159,\n",
       "        -0.05212995,\n",
       "        0.026087001,\n",
       "        0.055715147,\n",
       "        0.04604927,\n",
       "        -0.051631037,\n",
       "        0.043623835,\n",
       "        0.017111024,\n",
       "        0.016049633,\n",
       "        0.008456452,\n",
       "        0.019351339,\n",
       "        0.04718687,\n",
       "        -0.041073773,\n",
       "        0.073475555,\n",
       "        -0.008643692,\n",
       "        0.14942159,\n",
       "        -0.013187059,\n",
       "        -0.015042254\n",
       "      ],\n",
       "      \"index\": 0\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"all-minilm-l6-v2\",\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 0,\n",
       "    \"completion_tokens\": 0,\n",
       "    \"total_tokens\": 0\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Embedding.create(\n",
    "    model = \"all-minilm-l6-v2\",\n",
    "    input = \"This is a super cool text embedding\"\n",
    ")\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
