{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST request successful!\n",
      "Response content: {'api_key': 'WhWKYrWIW0EpMuuMAxy7101ZEyWrGW0ZcselSOVOqxm0gBmkPQZoYFx0AlevqVDJ'}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:8080/openai/v1/register\"  # Replace this with the actual API endpoint\n",
    "\n",
    "# Data to be sent in the request body\n",
    "data = {\n",
    "    \"username\": \"test-user\",\n",
    "}\n",
    "\n",
    "# Headers to be added to the request\n",
    "headers = {\n",
    "    # \"Authorization\": \"Bearer YOUR_ACCESS_TOKEN\",  # Example of an authorization header\n",
    "    \"Content-Type\": \"application/json\",  # Example of a JSON content type header\n",
    "}\n",
    "\n",
    "# Make the POST request with headers\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Request was successful\n",
    "    print(\"POST request successful!\")\n",
    "    print(\"Response content:\", response.json())\n",
    "else:\n",
    "    # Request failed\n",
    "    print(\"POST request failed! Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST request successful!\n",
      "Response content: {'data': [{'created': 0, 'id': 'text-embedding-ada-002', 'object': '', 'owned_by': 'Defense Unicorns', 'permission': [], 'root': '', 'parent': ''}, {'created': 0, 'id': 'instructorxl', 'object': '', 'owned_by': 'Defense Unicorns', 'permission': [], 'root': '', 'parent': ''}, {'created': 0, 'id': 'whisper-1', 'object': '', 'owned_by': 'Defense Unicorns', 'permission': [], 'root': '', 'parent': ''}, {'created': 0, 'id': 'mpt-7b-chat', 'object': '', 'owned_by': '', 'permission': [], 'root': '', 'parent': ''}, {'created': 0, 'id': 'ctransformers', 'object': '', 'owned_by': 'Defense Unicorns', 'permission': [], 'root': '', 'parent': ''}]}\n"
     ]
    }
   ],
   "source": [
    "api_key = \"Obhs4zeQ2ZnQqVFwVx4W7jCoVutFhVI8CQYAzy3UjMOAA5QeS1THublmH8a9c2Gj\"\n",
    "\n",
    "url = \"http://localhost:8080/openai/v1/models\"  # Replace this with the actual API endpoint\n",
    "\n",
    "# Data to be sent in the request body\n",
    "data = {}\n",
    "\n",
    "# Headers to be added to the request\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",  # Example of an authorization header\n",
    "    \"Content-Type\": \"application/json\",  # Example of a JSON content type header\n",
    "}\n",
    "\n",
    "# Make the GET request with headers\n",
    "response = requests.get(url, json=data, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Request was successful\n",
    "    print(\"POST request successful!\")\n",
    "    print(\"Response content:\", response.json())\n",
    "else:\n",
    "    # Request failed\n",
    "    print(\"POST request failed! Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"Obhs4zeQ2ZnQqVFwVx4W7jCoVutFhVI8CQYAzy3UjMOAA5QeS1THublmH8a9c2Gj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How long is the hash of the token (taken from the database)?\n",
    "\n",
    "...so the 88 character length of a base64 encode of a sha-512 hash includes the trailing `==` characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"iwti++nECuPkEPrdQEaZVu9pFkF1hpuAeGgeZg0nsJn+LIip3HzaaQgRrAFyEPsxIsFBAdJSNiya9PCuOEcT5Q==\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Point to your own url\n",
    "openai.api_base = \"http://localhost:8080/openai/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Now we're actually checking API keys...\u001b[39;00m\n\u001b[1;32m      2\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFreeTheModels\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(openai\u001b[39m.\u001b[39;49mModel\u001b[39m.\u001b[39;49mlist())\n",
      "File \u001b[0;32m~/Developer/dayofthepenguin/leapfrogai/venv/lib/python3.10/site-packages/openai/api_resources/abstract/listable_api_resource.py:60\u001b[0m, in \u001b[0;36mListableAPIResource.list\u001b[0;34m(cls, api_key, request_id, api_version, organization, api_base, api_type, **params)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[1;32m     43\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m     51\u001b[0m ):\n\u001b[1;32m     52\u001b[0m     requestor, url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__prepare_list_requestor(\n\u001b[1;32m     53\u001b[0m         api_key,\n\u001b[1;32m     54\u001b[0m         api_version,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m         api_type,\n\u001b[1;32m     58\u001b[0m     )\n\u001b[0;32m---> 60\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m     61\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params, request_id\u001b[39m=\u001b[39;49mrequest_id\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     openai_object \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[1;32m     64\u001b[0m         response, api_key, api_version, organization\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     66\u001b[0m     openai_object\u001b[39m.\u001b[39m_retrieve_params \u001b[39m=\u001b[39m params\n",
      "File \u001b[0;32m~/Developer/dayofthepenguin/leapfrogai/venv/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Developer/dayofthepenguin/leapfrogai/venv/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/dayofthepenguin/leapfrogai/venv/lib/python3.10/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39;49mdata, rheaders, stream_error\u001b[39m=\u001b[39;49mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Developer/dayofthepenguin/leapfrogai/venv/lib/python3.10/site-packages/openai/api_requestor.py:418\u001b[0m, in \u001b[0;36mAPIRequestor.handle_error_response\u001b[0;34m(self, rbody, rcode, resp, rheaders, stream_error)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minternal_message\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m error_data:\n\u001b[1;32m    414\u001b[0m     error_data[\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m error_data[\u001b[39m\"\u001b[39m\u001b[39minternal_message\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    416\u001b[0m util\u001b[39m.\u001b[39mlog_info(\n\u001b[1;32m    417\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOpenAI API error received\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m--> 418\u001b[0m     error_code\u001b[39m=\u001b[39merror_data\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    419\u001b[0m     error_type\u001b[39m=\u001b[39merror_data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    420\u001b[0m     error_message\u001b[39m=\u001b[39merror_data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    421\u001b[0m     error_param\u001b[39m=\u001b[39merror_data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mparam\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    422\u001b[0m     stream_error\u001b[39m=\u001b[39mstream_error,\n\u001b[1;32m    423\u001b[0m )\n\u001b[1;32m    425\u001b[0m \u001b[39m# Rate limits were previously coded as 400's with code 'rate_limit'\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39mif\u001b[39;00m rcode \u001b[39m==\u001b[39m \u001b[39m429\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Now we're actually checking API keys...\n",
    "openai.api_key = 'FreeTheModels'\n",
    "\n",
    "print(openai.Model.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"whisper-1\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"Defense Unicorns\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"mpt-7b-chat\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"ctransformers\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"Defense Unicorns\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"text-embedding-ada-002\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"Defense Unicorns\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"created\": 0,\n",
      "      \"id\": \"instructorxl\",\n",
      "      \"object\": \"\",\n",
      "      \"owned_by\": \"Defense Unicorns\",\n",
      "      \"permission\": [],\n",
      "      \"root\": \"\",\n",
      "      \"parent\": \"\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Use your API key from above\n",
    "openai.api_key = 'WhWKYrWIW0EpMuuMAxy7101ZEyWrGW0ZcselSOVOqxm0gBmkPQZoYFx0AlevqVDJ'\n",
    "\n",
    "# Point to your own url\n",
    "openai.api_base = \"http://localhost:8080/openai/v1\"\n",
    "print(openai.Model.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful programming assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you write a python program to download a series of files from s3 and search the contents of each file for email addresses?\"},\n",
    "]\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful programming assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"can you tell me about your day?\"},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I can help you with that. Here's a sample Python program that downloads a series of files from S3 and searches their contents for email addresses:\n",
      "```python\n",
      "import boto3\n",
      "import re\n",
      "# Set up S3 client\n",
      "s3 = boto3.client('s3')\n",
      "# Define the S3 bucket and prefix\n",
      "bucket_name = 'your-bucket-name'\n",
      "prefix = 'your-prefix'\n",
      "# Download all files from S3\n",
      "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
      "files = response['Contents']\n",
      "# Loop through each file and search for email addresses\n",
      "for file in files:\n",
      "    file_key = file['Key']\n",
      "    file_obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
      "    with file_obj['Body'].read().new('utf-8') as f:\n",
      "        file_contents = f.read()\n",
      "        email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
      "        emails = re.findall(email_regex, file_contents)\n",
      "        print(f\"Found {len(emails)} email addresses in {file_key}\")\n",
      "```\n",
      "Note that this program assumes that the email addresses are contained within the contents of the files. If the email addresses are in file names or metadata, you may need to modify the program to search for them in different locations."
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model='mpt-7b-chat',\n",
    "    messages=messages,\n",
    "    stream=True  # this time, we set stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk[\"choices\"][0][\"message\"][\"content\"], end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
